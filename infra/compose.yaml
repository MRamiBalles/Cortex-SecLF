services:
  # ---------------------------------------------
  # AI Engine: Ollama (Headless)
  # ---------------------------------------------
  ai-engine:
    image: ollama/ollama:latest
    container_name: cslf-ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    networks:
      - cslf-net
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:11434/api/tags" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s

  # ---------------------------------------------
  # Vector Database: ChromaDB
  # ---------------------------------------------
  vector-db:
    image: chromadb/chroma:latest
    container_name: cslf-chromadb
    volumes:
      - ../data/vector_db:/chroma/chroma
    ports:
      - "8000:8000"
    networks:
      - cslf-net
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma/chroma
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat" ]
      interval: 10s
      timeout: 5s
      retries: 3

  # ---------------------------------------------
  # Backend: FastAPI
  # ---------------------------------------------
  backend:
    build:
      context: ../backend
      dockerfile: ../infra/docker/backend.Dockerfile
    container_name: cslf-backend
    volumes:
      - ../backend:/app
      - ../data:/data
      - /var/run/docker.sock:/var/run/docker.sock # For Agent Lab Control
    ports:
      - "8008:8000"
    environment:
      - OLLAMA_BASE_URL=http://ai-engine:11434
      - CHROMA_DB_HOST=vector-db
      - CHROMA_DB_PORT=8000
    depends_on:
      ai-engine:
        condition: service_healthy
      vector-db:
        condition: service_healthy
    networks:
      - cslf-net

  # ---------------------------------------------
  # Frontend: Next.js
  # ---------------------------------------------
  frontend:
    build:
      context: ../frontend
      dockerfile: ../infra/docker/frontend.Dockerfile
    container_name: cslf-frontend
    volumes:
      - ../frontend:/app
      - /app/node_modules
    ports:
      - "3000:3000"
    environment:
      - API_BASE_URL=http://backend:8000
    depends_on:
      backend:
        condition: service_started
    networks:
      - cslf-net

  # ---------------------------------------------
  # Module 3: Rogue Agent (Containment Lab)
  # ---------------------------------------------
  rogue-agent:
    image: python:3.11-slim
    container_name: cslf-rogue-agent
    command: [ "tail", "-f", "/dev/null" ] # Idle until triggered
    init: true
    read_only: true # Filesystem Lock
    tmpfs:
      - /tmp
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 512M
          pids: 50 # Prevent Fork Bombs
    networks:
      - agent-jail-net # Isolated Network

networks:
  cslf-net:
    driver: bridge
  agent-jail-net:
    internal: true # No Internet Access

volumes:
  ollama_data:
